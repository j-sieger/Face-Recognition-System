{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of FaceNet_J.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MEHOiOQh7jyk","colab_type":"code","outputId":"dfb7d547-26d7-465a-8a8a-c3a4d10155e7","executionInfo":{"status":"ok","timestamp":1574336719179,"user_tz":-330,"elapsed":41305,"user":{"displayName":"jani basha","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mABIbrZBnv5a4a9GpkcwlNGArEFkk1cN2d92Qzo1Q=s64","userId":"01940010228818985276"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gvE6TPuD-ELG","colab_type":"code","outputId":"b28d3e6e-d3b3-4237-9a40-1239d6addf86","executionInfo":{"status":"ok","timestamp":1574336719602,"user_tz":-330,"elapsed":40245,"user":{"displayName":"jani basha","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mABIbrZBnv5a4a9GpkcwlNGArEFkk1cN2d92Qzo1Q=s64","userId":"01940010228818985276"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["#Change the working directory\n","import os\n","import gc\n","os.chdir('/content/gdrive/My Drive/Colab Notebooks/FaceRecognition')\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","os.listdir()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['model',\n"," 'Sharukha-1.jpg',\n"," 'sharukhSalman.png',\n"," 'Dataset',\n"," 'CheckPoints',\n"," 'FaceNet_J.ipynb',\n"," 'output',\n"," '.ipynb_checkpoints',\n"," 'debug.JPG',\n"," 'Copy of FaceNet_J.ipynb']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"Njl_yy37O_ud","colab_type":"code","outputId":"c26fe0cd-6158-4b19-eaf7-f365037ce1a4","executionInfo":{"status":"ok","timestamp":1574336719603,"user_tz":-330,"elapsed":3153,"user":{"displayName":"jani basha","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mABIbrZBnv5a4a9GpkcwlNGArEFkk1cN2d92Qzo1Q=s64","userId":"01940010228818985276"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["os.listdir()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['model',\n"," 'Sharukha-1.jpg',\n"," 'sharukhSalman.png',\n"," 'Dataset',\n"," 'CheckPoints',\n"," 'FaceNet_J.ipynb',\n"," 'output',\n"," '.ipynb_checkpoints',\n"," 'debug.JPG',\n"," 'Copy of FaceNet_J.ipynb']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"jD45GmJiPn5h","colab_type":"code","outputId":"2a7e3d66-497e-4222-ddb0-8d4d1ab37eef","executionInfo":{"status":"ok","timestamp":1574336727861,"user_tz":-330,"elapsed":9853,"user":{"displayName":"jani basha","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mABIbrZBnv5a4a9GpkcwlNGArEFkk1cN2d92Qzo1Q=s64","userId":"01940010228818985276"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["!sudo pip install mtcnn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting mtcnn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.2.5)\n","Collecting opencv-python>=4.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/7e/bd5425f4dacb73367fddc71388a47c1ea570839197c2bcad86478e565186/opencv_python-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (28.7MB)\n","\u001b[K     |████████████████████████████████| 28.7MB 34.4MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.0.8)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.3.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.17.4)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.8.0)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: opencv-python, mtcnn\n","  Found existing installation: opencv-python 3.4.7.28\n","    Uninstalling opencv-python-3.4.7.28:\n","      Successfully uninstalled opencv-python-3.4.7.28\n","Successfully installed mtcnn-0.1.0 opencv-python-4.1.1.26\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Rxz9XZiO4vy","colab_type":"code","outputId":"ca500bfa-dc45-465b-bb35-c49004f1a7e0","executionInfo":{"status":"ok","timestamp":1574336729685,"user_tz":-330,"elapsed":10095,"user":{"displayName":"jani basha","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mABIbrZBnv5a4a9GpkcwlNGArEFkk1cN2d92Qzo1Q=s64","userId":"01940010228818985276"}},"colab":{"base_uri":"https://localhost:8080/","height":97}},"source":["# confirm mtcnn was installed correctly\n","import mtcnn\n","# print version\n","print(mtcnn.__version__)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["0.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vH7qIGQ7QssE","colab_type":"code","colab":{}},"source":["# demonstrate face detection on 5 Celebrity Faces Dataset\n","from os import listdir\n","from PIL import Image\n","from numpy import asarray\n","from matplotlib import pyplot\n","from mtcnn.mtcnn import MTCNN\n"," \n","# extract a single face from a given photograph\n","def extract_face(filename, required_size=(160, 160)):\n","\tface_array = list()\n","\t# load image from file\n","\timage = Image.open(filename)\n","\t# convert to RGB, if needed\n","\timage = image.convert('RGB')\n","\t# convert to array\n","\tpixels = asarray(image)\n","\t# create the detector, using default weights\n","\tdetector = MTCNN()\n","\t# detect faces in the image\n","\tresults = detector.detect_faces(pixels)\n","\t# extract the bounding box from the first face\n","\tfor resulti in results:\n","\t\tx1, y1, width, height = resulti['box']\n","\t\t# bug fix\n","\t\tx1, y1 = abs(x1), abs(y1)\n","\t\tx2, y2 = x1 + width, y1 + height\n","\t\t# extract the face\n","\t\tface = pixels[y1:y2, x1:x2]\n","\t\t# resize pixels to the model size\n","\t\timage = Image.fromarray(face)\n","\t\timage = image.resize(required_size)\n","\t\tface_array.append(asarray(image))\n","\treturn face_array\n"," \n","# specify folder to plot\n","folder = './Dataset/train/Salman/'\n","i = 1\n","# enumerate files\n","for filename in listdir(folder):\n","\t# path\n","\t#path = folder + filename\n","\tpath = '/content/gdrive/My Drive/Colab Notebooks/FaceRecognition/debug.JPG'\n","\t# get face\n","\tface = extract_face(path)\n","\tfor facei in face:\n","\t\t#print(i, face.shape)\n","\t\t# plot\n","\t\tpyplot.subplot(2, 7, i)\n","\t\tpyplot.axis('off')\n","\t\tpyplot.imshow(facei)\n","\t\ti += 1\n","\t\tpyplot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y28i2EPdh1oc","colab_type":"code","colab":{}},"source":["!pwd\n","results.shape()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMXFgqZaP2Pk","colab_type":"code","outputId":"1723e656-ea13-4530-e37d-8e1745d84642","executionInfo":{"status":"ok","timestamp":1574337691534,"user_tz":-330,"elapsed":954903,"user":{"displayName":"jani basha","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mABIbrZBnv5a4a9GpkcwlNGArEFkk1cN2d92Qzo1Q=s64","userId":"01940010228818985276"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["# face detection for the 5 Celebrity Faces Dataset\n","from os import listdir\n","from os.path import isdir\n","from PIL import Image\n","from matplotlib import pyplot\n","from numpy import savez_compressed\n","from numpy import asarray\n","from mtcnn.mtcnn import MTCNN\n"," \n","# extract a single face from a given photograph\n","def extract_face(filename, required_size=(160, 160)):\n","\t# load image from file\n","\timage = Image.open(filename)\n","\t# convert to RGB, if needed\n","\timage = image.convert('RGB')\n","\t# convert to array\n","\tpixels = asarray(image)\n","\t# create the detector, using default weights\n","\tdetector = MTCNN()\n","\t# detect faces in the image\n","\tresults = detector.detect_faces(pixels)\n","\t# extract the bounding box from the first face\n","\tx1, y1, width, height = results[0]['box']\n","\t# bug fix\n","\tx1, y1 = abs(x1), abs(y1)\n","\tx2, y2 = x1 + width, y1 + height\n","\t# extract the face\n","\tface = pixels[y1:y2, x1:x2]\n","\t# resize pixels to the model size\n","\timage = Image.fromarray(face)\n","\timage = image.resize(required_size)\n","\tface_array = asarray(image)\n","\treturn face_array\n"," \n","# load images and extract faces for all images in a directory\n","def load_faces(directory):\n","\tfaces = list()\n","\t# enumerate files\n","\tfor filename in listdir(directory):\n","\t\t# path\n","\t\tpath = directory + filename\n","\t\t# get face\n","\t\tface = extract_face(path)\n","\t\t# store\n","\t\tfaces.append(face)\n","\treturn faces\n"," \n","# load a dataset that contains one subdir for each class that in turn contains images\n","def load_dataset(directory):\n","\tX, y = list(), list()\n","\t# enumerate folders, on per class\n","\tfor subdir in listdir(directory):\n","\t\t# path\n","\t\tpath = directory + subdir + '/'\n","\t\t# skip any files that might be in the dir\n","\t\tif not isdir(path):\n","\t\t\tcontinue\n","\t\t# load all faces in the subdirectory\n","\t\tfaces = load_faces(path)\n","\t\t# create labels\n","\t\tlabels = [subdir for _ in range(len(faces))]\n","\t\t# summarize progress\n","\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n","\t\t# store\n","\t\tX.extend(faces)\n","\t\ty.extend(labels)\n","\treturn asarray(X), asarray(y)\n"," \n","# load train dataset\n","\n","trainX, trainy = load_dataset('./Dataset/train/')\n","print(trainX.shape, trainy.shape)\n","# load test dataset\n","testX, testy = load_dataset('./Dataset/val/')\n","# save arrays to one file in compressed format\n","savez_compressed('./CheckPoints/5-celebrity-faces-dataset.npz', trainX, trainy, testX, testy)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n",">loaded 7 examples for class: Mohanlal\n",">loaded 7 examples for class: Rajani\n",">loaded 8 examples for class: Chiranjeevi\n",">loaded 7 examples for class: Sharukh\n",">loaded 5 examples for class: Salman\n",">loaded 7 examples for class: SundarPichai\n",">loaded 5 examples for class: Alen\n",">loaded 7 examples for class: Elisa\n",">loaded 6 examples for class: Wangyi\n",">loaded 4 examples for class: Michale\n",">loaded 9 examples for class: EMP_01\n",">loaded 4 examples for class: Denis\n","(76, 160, 160, 3) (76,)\n",">loaded 4 examples for class: Chiranjeevi\n",">loaded 4 examples for class: Sharukh\n",">loaded 2 examples for class: Rajani\n",">loaded 6 examples for class: Salman\n",">loaded 2 examples for class: Mohanlal\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0y4eB95VoOxf","colab_type":"text"},"source":["Run the below cell when the new dataset is added"]},{"cell_type":"code","metadata":{"id":"RIl9dopynVPn","colab_type":"code","outputId":"9136cae8-9e92-4a18-86db-7d7853afcaa5","executionInfo":{"status":"ok","timestamp":1574337725726,"user_tz":-330,"elapsed":979475,"user":{"displayName":"jani basha","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mABIbrZBnv5a4a9GpkcwlNGArEFkk1cN2d92Qzo1Q=s64","userId":"01940010228818985276"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["# calculate a face embedding for each face in the dataset using facenet\n","from numpy import load\n","from numpy import expand_dims\n","from numpy import asarray\n","from numpy import savez_compressed\n","from keras.models import load_model\n"," \n","# get the face embedding for one face\n","def get_embedding(model, face_pixels):\n","\t# scale pixel values\n","\tface_pixels = face_pixels.astype('float32')\n","\t# standardize pixel values across channels (global)\n","\tmean, std = face_pixels.mean(), face_pixels.std()\n","\tface_pixels = (face_pixels - mean) / std\n","\t# transform face into one sample\n","\tsamples = expand_dims(face_pixels, axis=0)\n","\t# make prediction to get embedding\n","\tyhat = model.predict(samples)\n","\treturn yhat[0]\n"," \n","# load the face dataset\n","data = load('./CheckPoints/5-celebrity-faces-dataset.npz')\n","trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n","print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n","# load the facenet model\n","model = load_model('./model/facenet_keras.h5')\n","print('Loaded Model')\n","# convert each face in the train set to an embedding\n","newTrainX = list()\n","for face_pixels in trainX:\n","\tembedding = get_embedding(model, face_pixels)\n","\tnewTrainX.append(embedding)\n","newTrainX = asarray(newTrainX)\n","print(newTrainX.shape)\n","# convert each face in the test set to an embedding\n","newTestX = list()\n","for face_pixels in testX:\n","\tembedding = get_embedding(model, face_pixels)\n","\tnewTestX.append(embedding)\n","newTestX = asarray(newTestX)\n","print(newTestX.shape)\n","# save arrays to one file in compressed format\n","savez_compressed('././CheckPoints/5-celebrity-faces-embeddings.npz', newTrainX, trainy, newTestX, testy)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Loaded:  (76, 160, 160, 3) (76,) (18, 160, 160, 3) (18,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Loaded Model\n","(76, 128)\n","(18, 128)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E7dhEYamzRC9","colab_type":"text"},"source":["Below code block is not required"]},{"cell_type":"code","metadata":{"id":"B_YS2_wWSof1","colab_type":"code","colab":{}},"source":["# develop a classifier for the 5 Celebrity Faces Dataset\n","from numpy import load\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import Normalizer\n","from sklearn.svm import SVC\n","# load dataset\n","data = load('./CheckPoints/5-celebrity-faces-embeddings.npz')\n","trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n","print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n","# normalize input vectors\n","in_encoder = Normalizer(norm='l2')\n","trainX = in_encoder.transform(trainX)\n","testX = in_encoder.transform(testX)\n","# label encode targets\n","out_encoder = LabelEncoder()\n","out_encoder.fit(trainy)\n","trainy = out_encoder.transform(trainy)\n","testy = out_encoder.transform(testy)\n","# fit model\n","model = SVC(kernel='linear', probability=True)\n","model.fit(trainX, trainy)\n","# predict\n","yhat_train = model.predict(trainX)\n","yhat_test = model.predict(testX)\n","# score\n","score_train = accuracy_score(trainy, yhat_train)\n","score_test = accuracy_score(testy, yhat_test)\n","# summarize\n","print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wmkO11ApS16o","colab_type":"code","colab":{}},"source":["from imutils import face_utils\n","from PIL import Image\n","from numpy import asarray\n","from matplotlib import pyplot\n","from numpy import savez_compressed\n","from mtcnn.mtcnn import MTCNN\n","\n","detector = MTCNN()\n","\n","def resize_face(face_pixels, required_size=(160, 160)):\n","\t\t# resize pixels to the model size\n","\t\timage = Image.fromarray(face_pixels)\n","\t\timage = image.resize(required_size)\n","\t\tface_array=asarray(image)\n","\t\treturn face_array\n","\n","def get_embedding(FRmodel, img_pixels):\n","  #face_resize = ()\n","  required_size=(160, 160)\n","  #print(img_pixels.shape)\n","\t# scale pixel values\n","  face_pixels = resize_face(img_pixels)\n","  face_pixels = face_pixels.astype('float32')\n","  #print(face_pixels.shape)\n","\t# standardize pixel values across channels (global)\n","  mean, std = face_pixels.mean(), face_pixels.std()\n","  face_pixels = (face_pixels - mean) / std\n","\t# transform face into one sample\n","  samples = expand_dims(face_pixels, axis=0)\n","  # make prediction to get embedding\n","  yhat = FRmodel.predict(samples)\n","  return yhat[0]\n","\n","def recognize_face(FRmodel, face_pixels):\n","    data = load('./CheckPoints/5-celebrity-faces-embeddings.npz')\n","    trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n","    face_embedding = get_embedding(FRmodel, face_pixels)\n","    #print(face_embedding.shape)\n","    min_dist = 100\n","    identity = None\n","\n","    # normalize input vectors\n","    in_encoder = Normalizer(norm='l2')    \n","    #face_embedding = in_encoder.transform(face_embedding)\n","    samples = expand_dims(face_embedding, axis=0)\n","    # label encode targets\n","    out_encoder = LabelEncoder()\n","    out_encoder.fit(trainy)\n","    trainy = out_encoder.transform(trainy)\n","    # fit model\n","    model = SVC(kernel='linear', probability=True)\n","    model.fit(trainX, trainy)\n","    yhat_class = model.predict(samples)\n","    yhat_prob = model.predict_proba(samples)\n","    # get name\n","    class_index = yhat_class[0]\n","    #print(class_index)\n","    class_probability = yhat_prob[0,class_index] * 100\n","    predict_names = out_encoder.inverse_transform(yhat_class)\n","    #print(predict_names[0])\n","    #print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n","    #print('Expected: %s' % random_face_name[0])\n","    return predict_names[0],class_probability\n","    \n","\n","def extract_face(img_rgb, required_size=(160, 160)):\n","\tface_array = list()\n","\t# load image from file\n","\t#image = Image.open(filename)\n","\t#image = image.convert('RGB')\n","\t# convert to array\n","\tpixels = asarray(img_rgb)\n","\t# create the detector, using default weights\n","\tdetector = MTCNN()\n","\t# detect faces in the image\n","\tresults = detector.detect_faces(pixels)\n","\t# extract the bounding box from the first face\n","\tfor resulti in results:\n","\t\tx1, y1, width, height = resulti['box']\n","\t\t# bug fix\n","\t\tx1, y1 = abs(x1), abs(y1)\n","\t\tx2, y2 = x1 + width, y1 + height\n","\t\t# extract the face\n","\t\tface = pixels[y1:y2, x1:x2]\n","\t\t# resize pixels to the model size\n","\t\timage = Image.fromarray(face)\n","\t\timage = image.resize(required_size)\n","\t\tface_array.append(asarray(image))\n","\treturn face_array\n","\n","def extract_face_info(img, img_rgb, FRmodel):\n","    faces = detector.detect_faces(img_rgb)\n","    x, y, w, h = 0, 0, 0, 0\n","    if len(faces) > 0:\n","        for face in faces:\n","            #print(face.shape)\n","            #(x, y, w, h) = face_utils.rect_to_bb(face)\n","            (x, y, w, h) = face['box']\n","            #print(\"jani1\")\n","            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 0), 2)\n","            #print(\"jani2\")\n","            image = img[y:y + h, x:x + w]\n","            name, Prob = recognize_face(FRmodel, image)\n","            #print(name)\n","            #print(Prob)\n","            if Prob > 40:\n","                #cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 0), 2)\n","                cv2.putText(img, \"Face : \" + name, (x, y - 50), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n","                cv2.putText(img, \"Dist : \" + str(Prob), (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n","            #else:\n","                #cv2.putText(img, 'No matching faces', (x, y - 20), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 255), 2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rX33KcQRr1Rp","colab_type":"code","outputId":"803dacd5-d1fb-4927-81c2-249ceb4a6c60","executionInfo":{"status":"ok","timestamp":1574338011115,"user_tz":-330,"elapsed":268866,"user":{"displayName":"jani basha","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mABIbrZBnv5a4a9GpkcwlNGArEFkk1cN2d92Qzo1Q=s64","userId":"01940010228818985276"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# import the necessary packages\n","from random import choice\n","from numpy import load\n","from keras.models import load_model\n","from numpy import expand_dims\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import Normalizer\n","from sklearn.svm import SVC\n","from matplotlib import pyplot\n","\n","import cv2\n","from imutils import face_utils\n","import dlib\n","from google.colab.patches import cv2_imshow\n","\n","data = load('./CheckPoints/5-celebrity-faces-embeddings.npz')\n","trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n","FRmodel = load_model('./model/facenet_keras.h5')\n","print('Loaded Model')\n","#cap = cv2.VideoCapture(0)\n","\n","# initialize the video stream, pointer to output video file, and\n","# frame dimensions\n","#database = initialize()\n","cap = cv2.VideoCapture(\"/content/gdrive/My Drive/Colab Notebooks/FaceRecogn_Video/Dataset/Manufacturing_Industry_1.mp4\")\n","writer = None\n","(W, H) = (None, None)\n"," \n","# try to determine the total number of frames in the video file\n","try:\n","\tprop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n","\t\telse cv2.CAP_PROP_FRAME_COUNT\n","\ttotal = int(cap.get(prop))\n","\tprint(\"[INFO] {} total frames in video\".format(total))\n"," \n","# an error occurred while trying to determine the total\n","# number of frames in the video file\n","except:\n","\tprint(\"[INFO] could not determine # of frames in video\")\n","\tprint(\"[INFO] no approx. completion time can be provided\")\n","\ttotal = -1\n","  \n","while True:\n","    # load the input image and convert it to grayscale\n","    ret, img = cap.read()\n","    if not ret:\n","        break\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        \n","    # detect faces in the grayscale image\n","    try:\n","      extract_face_info(img, img_rgb, FRmodel)            \n","    except ValueError:\n","      pass\n","\n","    if writer is None:\n","        # initialize our video writer\n","\t\t    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n","\t\t    writer = cv2.VideoWriter(\"/content/gdrive/My Drive/Colab Notebooks/FaceRecognition/output/Manufacturing_Industry_1_Output.mp4\", fourcc, 30,(img.shape[1], img.shape[0]), True)\n","\n","    writer.write(img)\n","    k = cv2.waitKey(5) & 0xFF\n","    if k == 27:\n","        break\n","\n","writer.release()\n","cv2.destroyAllWindows()\n","cap.release()\n","print(\"Predictions saved to output directory\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Loaded Model\n","[INFO] could not determine # of frames in video\n","[INFO] no approx. completion time can be provided\n","Predictions saved to output directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hUZb0l5db201","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}